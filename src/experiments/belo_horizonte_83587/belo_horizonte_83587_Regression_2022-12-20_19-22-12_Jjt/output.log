Running:
main.py --output_dir experiments/belo_horizonte_83587/ --comment regression for belo_horizonte_83587 --name belo_horizonte_83587_Regression --records_file experiments/belo_horizonte_83587/belo_horizonte_83587_Regression.xls --data_dir datasets/files/belo_horizonte_83587/ --data_class wf --pattern TRAIN --val_pattern TEST --epochs 10 --lr 0.0001 --optimizer RAdam --pos_encoding learnable --task regression

Using device: cpu
Loading and preprocessing data ...
1919 samples may be used for training
639 samples will be used for validation
0 samples will be used for testing
Creating model ...
Model:
TSTransformerEncoderClassiregressor(
  (project_inp): Linear(in_features=5, out_features=64, bias=True)
  (pos_enc): LearnablePositionalEncoding(
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (transformer_encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): TransformerBatchNormEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (linear1): Linear(in_features=64, out_features=256, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=256, out_features=64, bias=True)
        (norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerBatchNormEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (linear1): Linear(in_features=64, out_features=256, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=256, out_features=64, bias=True)
        (norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
      (2): TransformerBatchNormEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (linear1): Linear(in_features=64, out_features=256, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=256, out_features=64, bias=True)
        (norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (dropout1): Dropout(p=0.1, inplace=False)
  (output_layer): Linear(in_features=1536, out_features=1, bias=True)
)
Total number of parameters: 153409
Trainable parameters: 153409
Evaluating on validation set ...
Validation runtime: 0.0 hours, 0.0 minutes, 0.20099854469299316 seconds

Avg val. time: 0.0 hours, 0.0 minutes, 0.20099854469299316 seconds
Avg batch val. time: 0.020099854469299315 seconds
Avg sample val. time: 0.0003145517131345746 seconds
Epoch 0 Validation Summary: epoch: 0.000000 | loss: 392.973824 | 
Starting training...
Epoch 1 Training Summary: epoch: 1.000000 | loss: 472.052064 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 1.8947196006774902 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8947196006774902 seconds
Avg batch train. time: 0.06315732002258301 seconds
Avg sample train. time: 0.000987347368774096 seconds
Evaluating on validation set ...
Validation runtime: 0.0 hours, 0.0 minutes, 0.1979966163635254 seconds

Avg val. time: 0.0 hours, 0.0 minutes, 0.19949758052825928 seconds
Avg batch val. time: 0.01994975805282593 seconds
Avg sample val. time: 0.00031220278642920076 seconds
Epoch 1 Validation Summary: epoch: 1.000000 | loss: 462.983455 | 
Epoch 2 Training Summary: epoch: 2.000000 | loss: 466.326245 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 2.138550043106079 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 2.0166348218917847 seconds
Avg batch train. time: 0.06722116072972616 seconds
Avg sample train. time: 0.0010508779686773239 seconds
Evaluating on validation set ...
Validation runtime: 0.0 hours, 0.0 minutes, 0.21499967575073242 seconds

Avg val. time: 0.0 hours, 0.0 minutes, 0.204664945602417 seconds
Avg batch val. time: 0.0204664945602417 seconds
Avg sample val. time: 0.0003202894297377418 seconds
Epoch 2 Validation Summary: epoch: 2.000000 | loss: 458.568775 | 
Epoch 3 Training Summary: epoch: 3.000000 | loss: 458.113427 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 1.8964049816131592 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.9765582084655762 seconds
Avg batch train. time: 0.0658852736155192 seconds
Avg sample train. time: 0.0010299938553754956 seconds
Epoch 4 Training Summary: epoch: 4.000000 | loss: 447.506902 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 2.1109304428100586 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 2.0101512670516968 seconds
Avg batch train. time: 0.06700504223505656 seconds
Avg sample train. time: 0.0010474993575047924 seconds
Evaluating on validation set ...
Validation runtime: 0.0 hours, 0.0 minutes, 0.26400065422058105 seconds

Avg val. time: 0.0 hours, 0.0 minutes, 0.219498872756958 seconds
Avg batch val. time: 0.0219498872756958 seconds
Avg sample val. time: 0.00034350371323467607 seconds
Epoch 4 Validation Summary: epoch: 4.000000 | loss: 441.635588 | 
Epoch 5 Training Summary: epoch: 5.000000 | loss: 435.423429 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 2.182122230529785 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 2.0445454597473143 seconds
Avg batch train. time: 0.06815151532491047 seconds
Avg sample train. time: 0.0010654223344175686 seconds
Epoch 6 Training Summary: epoch: 6.000000 | loss: 419.412217 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 2.2774405479431152 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 2.0833613077799478 seconds
Avg batch train. time: 0.06944537692599825 seconds
Avg sample train. time: 0.0010856494568941884 seconds
Evaluating on validation set ...
Validation runtime: 0.0 hours, 0.0 minutes, 0.23999905586242676 seconds

Avg val. time: 0.0 hours, 0.0 minutes, 0.22359890937805177 seconds
Avg batch val. time: 0.022359890937805178 seconds
Avg sample val. time: 0.0003499200459750419 seconds
Epoch 6 Validation Summary: epoch: 6.000000 | loss: 416.461213 | 
Epoch 7 Training Summary: epoch: 7.000000 | loss: 401.433543 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 1.9231717586517334 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 2.060477086475917 seconds
Avg batch train. time: 0.06868256954919724 seconds
Avg sample train. time: 0.0010737243806544644 seconds
Epoch 8 Training Summary: epoch: 8.000000 | loss: 380.361748 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 1.9591312408447266 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 2.0478088557720184 seconds
Avg batch train. time: 0.06826029519240061 seconds
Avg sample train. time: 0.0010671229055612395 seconds
Evaluating on validation set ...
Validation runtime: 0.0 hours, 0.0 minutes, 0.2110004425048828 seconds

Avg val. time: 0.0 hours, 0.0 minutes, 0.22149916489919028 seconds
Avg batch val. time: 0.022149916489919028 seconds
Avg sample val. time: 0.0003466340608751022 seconds
Epoch 8 Validation Summary: epoch: 8.000000 | loss: 379.760007 | 
Epoch 9 Training Summary: epoch: 9.000000 | loss: 356.855422 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 1.8292407989501953 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 2.0235235161251492 seconds
Avg batch train. time: 0.0674507838708383 seconds
Avg sample train. time: 0.0010544676999088844 seconds
Epoch 10 Training Summary: epoch: 10.000000 | loss: 332.088318 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 1.9125134944915771 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 2.012422513961792 seconds
Avg batch train. time: 0.06708075046539307 seconds
Avg sample train. time: 0.0010486829150400168 seconds
Evaluating on validation set ...
Validation runtime: 0.0 hours, 0.0 minutes, 0.20050311088562012 seconds

Avg val. time: 0.0 hours, 0.0 minutes, 0.21849972861153738 seconds
Avg batch val. time: 0.021849972861153737 seconds
Avg sample val. time: 0.0003419401073732979 seconds
Epoch 10 Validation Summary: epoch: 10.000000 | loss: 331.477408 | 
Best loss was 331.4774076315532. Other metrics: OrderedDict([('epoch', 10), ('loss', 331.4774076315532)])
All Done!
Total runtime: 0.0 hours, 0.0 minutes, 25.01958966255188 seconds

