Running:
main.py --output_dir experiments/belo_horizonte_83587/ --comment regression for belo_horizonte_83587 --name belo_horizonte_83587_Regression --records_file experiments/belo_horizonte_83587/belo_horizonte_83587_Regression.xls --data_dir datasets/files/belo_horizonte_83587/ --data_class wf --pattern TRAIN --val_pattern TEST --epochs 10 --lr 0.001 --optimizer RAdam --pos_encoding learnable --task regression

Using device: cpu
Loading and preprocessing data ...
1919 samples may be used for training
639 samples will be used for validation
0 samples will be used for testing
Creating model ...
Model:
TSTransformerEncoderClassiregressor(
  (project_inp): Linear(in_features=5, out_features=64, bias=True)
  (pos_enc): LearnablePositionalEncoding(
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (transformer_encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): TransformerBatchNormEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (linear1): Linear(in_features=64, out_features=256, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=256, out_features=64, bias=True)
        (norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerBatchNormEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (linear1): Linear(in_features=64, out_features=256, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=256, out_features=64, bias=True)
        (norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
      (2): TransformerBatchNormEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (linear1): Linear(in_features=64, out_features=256, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=256, out_features=64, bias=True)
        (norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (dropout1): Dropout(p=0.1, inplace=False)
  (output_layer): Linear(in_features=1536, out_features=1, bias=True)
)
Total number of parameters: 153409
Trainable parameters: 153409
Evaluating on validation set ...
Validation runtime: 0.0 hours, 0.0 minutes, 0.18640542030334473 seconds

Avg val. time: 0.0 hours, 0.0 minutes, 0.18640542030334473 seconds
Avg batch val. time: 0.018640542030334474 seconds
Avg sample val. time: 0.00029171427277518736 seconds
Epoch 0 Validation Summary: epoch: 0.000000 | loss: 774.395925 | 
Starting training...
Epoch 1 Training Summary: epoch: 1.000000 | loss: 463.110469 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 2.3035166263580322 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 2.3035166263580322 seconds
Avg batch train. time: 0.07678388754526774 seconds
Avg sample train. time: 0.001200373437393451 seconds
Evaluating on validation set ...
Validation runtime: 0.0 hours, 0.0 minutes, 0.24000334739685059 seconds

Avg val. time: 0.0 hours, 0.0 minutes, 0.21320438385009766 seconds
Avg batch val. time: 0.021320438385009764 seconds
Avg sample val. time: 0.0003336531828640026 seconds
Epoch 1 Validation Summary: epoch: 1.000000 | loss: 437.556417 | 
Epoch 2 Training Summary: epoch: 2.000000 | loss: 403.364384 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 2.0591416358947754 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 2.181329131126404 seconds
Avg batch train. time: 0.0727109710375468 seconds
Avg sample train. time: 0.0011367009542086522 seconds
Evaluating on validation set ...
Validation runtime: 0.0 hours, 0.0 minutes, 0.22603750228881836 seconds

Avg val. time: 0.0 hours, 0.0 minutes, 0.2174820899963379 seconds
Avg batch val. time: 0.02174820899963379 seconds
Avg sample val. time: 0.000340347558679715 seconds
Epoch 2 Validation Summary: epoch: 2.000000 | loss: 361.872332 | 
Epoch 3 Training Summary: epoch: 3.000000 | loss: 298.714353 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 2.028064012527466 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 2.1302407582600913 seconds
Avg batch train. time: 0.07100802527533638 seconds
Avg sample train. time: 0.0011100785608442372 seconds
Epoch 4 Training Summary: epoch: 4.000000 | loss: 170.042773 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 2.0882043838500977 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 2.1197316646575928 seconds
Avg batch train. time: 0.0706577221552531 seconds
Avg sample train. time: 0.0011046022223332949 seconds
Evaluating on validation set ...
Validation runtime: 0.0 hours, 0.0 minutes, 0.2330322265625 seconds

Avg val. time: 0.0 hours, 0.0 minutes, 0.22136962413787842 seconds
Avg batch val. time: 0.02213696241378784 seconds
Avg sample val. time: 0.00034643133667899595 seconds
Epoch 4 Validation Summary: epoch: 4.000000 | loss: 81.684427 | 
Epoch 5 Training Summary: epoch: 5.000000 | loss: 59.132355 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 2.0327954292297363 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 2.1023444175720214 seconds
Avg batch train. time: 0.07007814725240072 seconds
Avg sample train. time: 0.0010955416454257536 seconds
Epoch 6 Training Summary: epoch: 6.000000 | loss: 8.268629 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 2.139047622680664 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 2.108461618423462 seconds
Avg batch train. time: 0.07028205394744873 seconds
Avg sample train. time: 0.001098729347797531 seconds
Evaluating on validation set ...
Validation runtime: 0.0 hours, 0.0 minutes, 0.21700215339660645 seconds

Avg val. time: 0.0 hours, 0.0 minutes, 0.22049612998962403 seconds
Avg batch val. time: 0.022049612998962402 seconds
Avg sample val. time: 0.0003450643661809453 seconds
Epoch 6 Validation Summary: epoch: 6.000000 | loss: 2.608576 | 
Epoch 7 Training Summary: epoch: 7.000000 | loss: 2.613981 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 2.0981130599975586 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 2.106983252934047 seconds
Avg batch train. time: 0.07023277509780157 seconds
Avg sample train. time: 0.001097958964530509 seconds
Epoch 8 Training Summary: epoch: 8.000000 | loss: 1.602100 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 2.2325479984283447 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 2.1226788461208344 seconds
Avg batch train. time: 0.07075596153736115 seconds
Avg sample train. time: 0.0011061380125694813 seconds
Evaluating on validation set ...
Validation runtime: 0.0 hours, 0.0 minutes, 0.2590005397796631 seconds

Avg val. time: 0.0 hours, 0.0 minutes, 0.2269135316212972 seconds
Avg batch val. time: 0.02269135316212972 seconds
Avg sample val. time: 0.00035510724823364193 seconds
Epoch 8 Validation Summary: epoch: 8.000000 | loss: 5.098330 | 
Epoch 9 Training Summary: epoch: 9.000000 | loss: 1.191355 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 2.5688087940216064 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 2.1722488403320312 seconds
Avg batch train. time: 0.07240829467773438 seconds
Avg sample train. time: 0.0011319691716164832 seconds
Epoch 10 Training Summary: epoch: 10.000000 | loss: 0.997856 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 2.341374635696411 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 2.1891614198684692 seconds
Avg batch train. time: 0.07297204732894898 seconds
Avg sample train. time: 0.0011407823970132722 seconds
Evaluating on validation set ...
Validation runtime: 0.0 hours, 0.0 minutes, 0.25600123405456543 seconds

Avg val. time: 0.0 hours, 0.0 minutes, 0.23106891768319265 seconds
Avg batch val. time: 0.023106891768319267 seconds
Avg sample val. time: 0.0003616101998172029 seconds
Epoch 10 Validation Summary: epoch: 10.000000 | loss: 1.763221 | 
Best loss was 1.7632205467642006. Other metrics: OrderedDict([('epoch', 10), ('loss', 1.7632205467642006)])
All Done!
Total runtime: 0.0 hours, 0.0 minutes, 27.16826558113098 seconds

