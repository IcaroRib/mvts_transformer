Running:
main.py --output_dir experiments/brasilia_83378/ --comment regression for brasilia_83378 --name brasilia_83378_Regression --records_file experiments/brasilia_83378/brasilia_83378_Regression.xls --data_dir datasets/files/brasilia_83378/ --data_class wf --pattern TRAIN --val_pattern TEST --epochs 10 --lr 0.0005 --optimizer RAdam --pos_encoding learnable --task regression

Using device: cpu
Loading and preprocessing data ...
1919 samples may be used for training
640 samples will be used for validation
0 samples will be used for testing
Creating model ...
Model:
TSTransformerEncoderClassiregressor(
  (project_inp): Linear(in_features=5, out_features=64, bias=True)
  (pos_enc): LearnablePositionalEncoding(
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (transformer_encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): TransformerBatchNormEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (linear1): Linear(in_features=64, out_features=256, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=256, out_features=64, bias=True)
        (norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerBatchNormEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (linear1): Linear(in_features=64, out_features=256, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=256, out_features=64, bias=True)
        (norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
      (2): TransformerBatchNormEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (linear1): Linear(in_features=64, out_features=256, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=256, out_features=64, bias=True)
        (norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (dropout1): Dropout(p=0.1, inplace=False)
  (output_layer): Linear(in_features=1536, out_features=1, bias=True)
)
Total number of parameters: 153409
Trainable parameters: 153409
Evaluating on validation set ...
Validation runtime: 0.0 hours, 0.0 minutes, 0.16900920867919922 seconds

Avg val. time: 0.0 hours, 0.0 minutes, 0.16900920867919922 seconds
Avg batch val. time: 0.016900920867919923 seconds
Avg sample val. time: 0.0002640768885612488 seconds
Epoch 0 Validation Summary: epoch: 0.000000 | loss: 374.429024 | 
Starting training...
Epoch 1 Training Summary: epoch: 1.000000 | loss: 492.387844 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 1.6780388355255127 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.6780388355255127 seconds
Avg batch train. time: 0.055934627850850425 seconds
Avg sample train. time: 0.000874433994541695 seconds
Evaluating on validation set ...
Validation runtime: 0.0 hours, 0.0 minutes, 0.23600149154663086 seconds

Avg val. time: 0.0 hours, 0.0 minutes, 0.20250535011291504 seconds
Avg batch val. time: 0.020250535011291503 seconds
Avg sample val. time: 0.0003164146095514297 seconds
Epoch 1 Validation Summary: epoch: 1.000000 | loss: 465.366849 | 
Epoch 2 Training Summary: epoch: 2.000000 | loss: 460.823606 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 2.0400540828704834 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.859046459197998 seconds
Avg batch train. time: 0.06196821530659993 seconds
Avg sample train. time: 0.0009687579255851996 seconds
Evaluating on validation set ...
Validation runtime: 0.0 hours, 0.0 minutes, 0.23901009559631348 seconds

Avg val. time: 0.0 hours, 0.0 minutes, 0.2146735986073812 seconds
Avg batch val. time: 0.021467359860738118 seconds
Avg sample val. time: 0.0003354274978240331 seconds
Epoch 2 Validation Summary: epoch: 2.000000 | loss: 434.521353 | 
Epoch 3 Training Summary: epoch: 3.000000 | loss: 413.813361 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 2.04799747467041 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.9220301310221355 seconds
Avg batch train. time: 0.06406767103407118 seconds
Avg sample train. time: 0.0010015790156446772 seconds
Epoch 4 Training Summary: epoch: 4.000000 | loss: 342.411475 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 1.9025826454162598 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.9171682596206665 seconds
Avg batch train. time: 0.06390560865402221 seconds
Avg sample train. time: 0.000999045471402119 seconds
Evaluating on validation set ...
Validation runtime: 0.0 hours, 0.0 minutes, 0.21800732612609863 seconds

Avg val. time: 0.0 hours, 0.0 minutes, 0.21550703048706055 seconds
Avg batch val. time: 0.021550703048706054 seconds
Avg sample val. time: 0.0003367297351360321 seconds
Epoch 4 Validation Summary: epoch: 4.000000 | loss: 295.128044 | 
Epoch 5 Training Summary: epoch: 5.000000 | loss: 256.860254 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 1.8318166732788086 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.900097942352295 seconds
Avg batch train. time: 0.06333659807840983 seconds
Avg sample train. time: 0.0009901500481252188 seconds
Epoch 6 Training Summary: epoch: 6.000000 | loss: 170.611654 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 1.8320932388305664 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8887638250986736 seconds
Avg batch train. time: 0.06295879416995578 seconds
Avg sample train. time: 0.0009842437858773702 seconds
Evaluating on validation set ...
Validation runtime: 0.0 hours, 0.0 minutes, 0.21999716758728027 seconds

Avg val. time: 0.0 hours, 0.0 minutes, 0.2164050579071045 seconds
Avg batch val. time: 0.02164050579071045 seconds
Avg sample val. time: 0.00033813290297985077 seconds
Epoch 6 Validation Summary: epoch: 6.000000 | loss: 135.365532 | 
Epoch 7 Training Summary: epoch: 7.000000 | loss: 92.969601 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 1.8282511234283447 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8801191534314836 seconds
Avg batch train. time: 0.06267063844771611 seconds
Avg sample train. time: 0.000979739006478105 seconds
Epoch 8 Training Summary: epoch: 8.000000 | loss: 34.828969 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 1.7990005016326904 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8699793219566345 seconds
Avg batch train. time: 0.06233264406522115 seconds
Avg sample train. time: 0.0009744550922129414 seconds
Evaluating on validation set ...
Validation runtime: 0.0 hours, 0.0 minutes, 0.2180008888244629 seconds

Avg val. time: 0.0 hours, 0.0 minutes, 0.21667102972666422 seconds
Avg batch val. time: 0.02166710297266642 seconds
Avg sample val. time: 0.0003385484839479128 seconds
Epoch 8 Validation Summary: epoch: 8.000000 | loss: 10.204221 | 
Epoch 9 Training Summary: epoch: 9.000000 | loss: 7.375813 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 1.8015828132629395 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8623797098795574 seconds
Avg batch train. time: 0.06207932366265191 seconds
Avg sample train. time: 0.000970494898321812 seconds
Epoch 10 Training Summary: epoch: 10.000000 | loss: 2.967421 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 1.8187744617462158 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.858019185066223 seconds
Avg batch train. time: 0.06193397283554077 seconds
Avg sample train. time: 0.0009682226081637431 seconds
Evaluating on validation set ...
Validation runtime: 0.0 hours, 0.0 minutes, 0.2070019245147705 seconds

Avg val. time: 0.0 hours, 0.0 minutes, 0.215289728982108 seconds
Avg batch val. time: 0.021528972898210798 seconds
Avg sample val. time: 0.0003363902015345437 seconds
Epoch 10 Validation Summary: epoch: 10.000000 | loss: 1.284232 | 
Best loss was 1.2842318832874298. Other metrics: OrderedDict([('epoch', 10), ('loss', 1.2842318832874298)])
All Done!
Total runtime: 0.0 hours, 0.0 minutes, 23.559605598449707 seconds

