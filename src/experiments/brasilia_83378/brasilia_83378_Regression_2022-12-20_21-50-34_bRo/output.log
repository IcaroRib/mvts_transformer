Running:
main.py --output_dir experiments/brasilia_83378/ --comment regression for brasilia_83378 --name brasilia_83378_Regression --records_file experiments/brasilia_83378/brasilia_83378_Regression.xls --data_dir datasets/files/brasilia_83378/ --data_class wf --pattern TRAIN --val_pattern TEST --epochs 10 --lr 0.01 --optimizer RAdam --pos_encoding learnable --task regression

Using device: cpu
Loading and preprocessing data ...
1919 samples may be used for training
640 samples will be used for validation
0 samples will be used for testing
Creating model ...
Model:
TSTransformerEncoderClassiregressor(
  (project_inp): Linear(in_features=5, out_features=64, bias=True)
  (pos_enc): LearnablePositionalEncoding(
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (transformer_encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): TransformerBatchNormEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (linear1): Linear(in_features=64, out_features=256, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=256, out_features=64, bias=True)
        (norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerBatchNormEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (linear1): Linear(in_features=64, out_features=256, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=256, out_features=64, bias=True)
        (norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
      (2): TransformerBatchNormEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (linear1): Linear(in_features=64, out_features=256, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=256, out_features=64, bias=True)
        (norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (dropout1): Dropout(p=0.1, inplace=False)
  (output_layer): Linear(in_features=1536, out_features=1, bias=True)
)
Total number of parameters: 153409
Trainable parameters: 153409
Evaluating on validation set ...
Validation runtime: 0.0 hours, 0.0 minutes, 0.1805579662322998 seconds

Avg val. time: 0.0 hours, 0.0 minutes, 0.1805579662322998 seconds
Avg batch val. time: 0.01805579662322998 seconds
Avg sample val. time: 0.00028212182223796844 seconds
Epoch 0 Validation Summary: epoch: 0.000000 | loss: 494.516083 | 
Starting training...
Epoch 1 Training Summary: epoch: 1.000000 | loss: 321.959386 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 1.6126453876495361 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.6126453876495361 seconds
Avg batch train. time: 0.053754846254984535 seconds
Avg sample train. time: 0.000840357158754318 seconds
Evaluating on validation set ...
Validation runtime: 0.0 hours, 0.0 minutes, 0.1960010528564453 seconds

Avg val. time: 0.0 hours, 0.0 minutes, 0.18827950954437256 seconds
Avg batch val. time: 0.018827950954437254 seconds
Avg sample val. time: 0.0002941867336630821 seconds
Epoch 1 Validation Summary: epoch: 1.000000 | loss: 28.006544 | 
Epoch 2 Training Summary: epoch: 2.000000 | loss: 16.670174 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 1.640615701675415 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.6266305446624756 seconds
Avg batch train. time: 0.05422101815541585 seconds
Avg sample train. time: 0.0008476448903921186 seconds
Evaluating on validation set ...
Validation runtime: 0.0 hours, 0.0 minutes, 0.20593690872192383 seconds

Avg val. time: 0.0 hours, 0.0 minutes, 0.194165309270223 seconds
Avg batch val. time: 0.0194165309270223 seconds
Avg sample val. time: 0.00030338329573472345 seconds
Epoch 2 Validation Summary: epoch: 2.000000 | loss: 5.790761 | 
Epoch 3 Training Summary: epoch: 3.000000 | loss: 1.831669 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 1.661879539489746 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.6383802096048992 seconds
Avg batch train. time: 0.05461267365349664 seconds
Avg sample train. time: 0.0008537676965111512 seconds
Epoch 4 Training Summary: epoch: 4.000000 | loss: 1.358185 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 1.6323206424713135 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.6368653178215027 seconds
Avg batch train. time: 0.05456217726071676 seconds
Avg sample train. time: 0.0008529782792191259 seconds
Evaluating on validation set ...
Validation runtime: 0.0 hours, 0.0 minutes, 0.18449974060058594 seconds

Avg val. time: 0.0 hours, 0.0 minutes, 0.19174891710281372 seconds
Avg batch val. time: 0.01917489171028137 seconds
Avg sample val. time: 0.00029960768297314643 seconds
Epoch 4 Validation Summary: epoch: 4.000000 | loss: 2.030852 | 
Epoch 5 Training Summary: epoch: 5.000000 | loss: 0.775651 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 1.6790409088134766 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.6453004360198975 seconds
Avg batch train. time: 0.05484334786732992 seconds
Avg sample train. time: 0.0008573738593120883 seconds
Epoch 6 Training Summary: epoch: 6.000000 | loss: 0.930527 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 1.7937040328979492 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.670034368832906 seconds
Avg batch train. time: 0.0556678122944302 seconds
Avg sample train. time: 0.0008702628289905712 seconds
Evaluating on validation set ...
Validation runtime: 0.0 hours, 0.0 minutes, 0.19793128967285156 seconds

Avg val. time: 0.0 hours, 0.0 minutes, 0.1929853916168213 seconds
Avg batch val. time: 0.01929853916168213 seconds
Avg sample val. time: 0.00030153967440128327 seconds
Epoch 6 Validation Summary: epoch: 6.000000 | loss: 3.700516 | 
Epoch 7 Training Summary: epoch: 7.000000 | loss: 1.525223 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 1.7177648544311523 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.6768530096326555 seconds
Avg batch train. time: 0.05589510032108851 seconds
Avg sample train. time: 0.0008738160550456777 seconds
Epoch 8 Training Summary: epoch: 8.000000 | loss: 1.193349 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 1.6914761066436768 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.6786808967590332 seconds
Avg batch train. time: 0.055956029891967775 seconds
Avg sample train. time: 0.0008747685756951711 seconds
Evaluating on validation set ...
Validation runtime: 0.0 hours, 0.0 minutes, 0.1856069564819336 seconds

Avg val. time: 0.0 hours, 0.0 minutes, 0.19175565242767334 seconds
Avg batch val. time: 0.019175565242767333 seconds
Avg sample val. time: 0.00029961820691823957 seconds
Epoch 8 Validation Summary: epoch: 8.000000 | loss: 7.672613 | 
Epoch 9 Training Summary: epoch: 9.000000 | loss: 1.587520 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 1.7041783332824707 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.6815139452616374 seconds
Avg batch train. time: 0.05605046484205458 seconds
Avg sample train. time: 0.0008762448907043447 seconds
Epoch 10 Training Summary: epoch: 10.000000 | loss: 1.586549 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 1.7201080322265625 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.68537335395813 seconds
Avg batch train. time: 0.05617911179860433 seconds
Avg sample train. time: 0.0008782560468776081 seconds
Evaluating on validation set ...
Validation runtime: 0.0 hours, 0.0 minutes, 0.20100688934326172 seconds

Avg val. time: 0.0 hours, 0.0 minutes, 0.19307725770132883 seconds
Avg batch val. time: 0.019307725770132882 seconds
Avg sample val. time: 0.0003016832151583263 seconds
Epoch 10 Validation Summary: epoch: 10.000000 | loss: 5.852569 | 
Best loss was 2.030851978063583. Other metrics: OrderedDict([('epoch', 4), ('loss', 2.030851978063583)])
All Done!
Total runtime: 0.0 hours, 0.0 minutes, 21.565893411636353 seconds

