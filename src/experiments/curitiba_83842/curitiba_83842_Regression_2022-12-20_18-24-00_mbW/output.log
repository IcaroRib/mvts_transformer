Running:
main.py --output_dir experiments/curitiba_83842/ --comment regression for curitiba_83842 --name curitiba_83842_Regression --records_file experiments/curitiba_83842/curitiba_83842_Regression.xls --data_dir datasets/files/curitiba_83842/ --data_class wf --pattern TRAIN --val_pattern TEST --epochs 10 --lr 0.01 --optimizer RAdam --pos_encoding learnable --task regression

Using device: cpu
Loading and preprocessing data ...
1905 samples may be used for training
635 samples will be used for validation
0 samples will be used for testing
Creating model ...
Model:
TSTransformerEncoderClassiregressor(
  (project_inp): Linear(in_features=5, out_features=64, bias=True)
  (pos_enc): LearnablePositionalEncoding(
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (transformer_encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): TransformerBatchNormEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (linear1): Linear(in_features=64, out_features=256, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=256, out_features=64, bias=True)
        (norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerBatchNormEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (linear1): Linear(in_features=64, out_features=256, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=256, out_features=64, bias=True)
        (norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
      (2): TransformerBatchNormEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (linear1): Linear(in_features=64, out_features=256, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=256, out_features=64, bias=True)
        (norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (dropout1): Dropout(p=0.1, inplace=False)
  (output_layer): Linear(in_features=1536, out_features=1, bias=True)
)
Total number of parameters: 153409
Trainable parameters: 153409
Evaluating on validation set ...
Validation runtime: 0.0 hours, 0.0 minutes, 0.1909925937652588 seconds

Avg val. time: 0.0 hours, 0.0 minutes, 0.1909925937652588 seconds
Avg batch val. time: 0.01909925937652588 seconds
Avg sample val. time: 0.00030077573821300595 seconds
Epoch 0 Validation Summary: epoch: 0.000000 | loss: 142.410943 | 
Starting training...
Epoch 1 Training Summary: epoch: 1.000000 | loss: 191.507678 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 1.5900967121124268 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.5900967121124268 seconds
Avg batch train. time: 0.05300322373708089 seconds
Avg sample train. time: 0.0008346964368044235 seconds
Evaluating on validation set ...
Validation runtime: 0.0 hours, 0.0 minutes, 0.17800021171569824 seconds

Avg val. time: 0.0 hours, 0.0 minutes, 0.18449640274047852 seconds
Avg batch val. time: 0.01844964027404785 seconds
Avg sample val. time: 0.00029054551612673783 seconds
Epoch 1 Validation Summary: epoch: 1.000000 | loss: 21.226923 | 
Epoch 2 Training Summary: epoch: 2.000000 | loss: 6.537906 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 1.9187564849853516 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7544265985488892 seconds
Avg batch train. time: 0.058480886618296306 seconds
Avg sample train. time: 0.000920958844382619 seconds
Evaluating on validation set ...
Validation runtime: 0.0 hours, 0.0 minutes, 0.24805712699890137 seconds

Avg val. time: 0.0 hours, 0.0 minutes, 0.20568331082661948 seconds
Avg batch val. time: 0.02056833108266195 seconds
Avg sample val. time: 0.0003239107257112118 seconds
Epoch 2 Validation Summary: epoch: 2.000000 | loss: 4.775598 | 
Epoch 3 Training Summary: epoch: 3.000000 | loss: 1.781269 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 2.374373197555542 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.9610754648844402 seconds
Avg batch train. time: 0.06536918216281468 seconds
Avg sample train. time: 0.0010294359395718847 seconds
Epoch 4 Training Summary: epoch: 4.000000 | loss: 1.646312 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 2.2050206661224365 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 2.022061765193939 seconds
Avg batch train. time: 0.06740205883979797 seconds
Avg sample train. time: 0.0010614497455086296 seconds
Evaluating on validation set ...
Validation runtime: 0.0 hours, 0.0 minutes, 0.2380084991455078 seconds

Avg val. time: 0.0 hours, 0.0 minutes, 0.21376460790634155 seconds
Avg batch val. time: 0.021376460790634155 seconds
Avg sample val. time: 0.0003366371778052623 seconds
Epoch 4 Validation Summary: epoch: 4.000000 | loss: 1.163578 | 
Epoch 5 Training Summary: epoch: 5.000000 | loss: 1.115224 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 1.9818367958068848 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 2.0140167713165282 seconds
Avg batch train. time: 0.0671338923772176 seconds
Avg sample train. time: 0.0010572266516097261 seconds
Epoch 6 Training Summary: epoch: 6.000000 | loss: 1.149022 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 1.8870728015899658 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.9928594430287678 seconds
Avg batch train. time: 0.06642864810095893 seconds
Avg sample train. time: 0.0010461204425347864 seconds
Evaluating on validation set ...
Validation runtime: 0.0 hours, 0.0 minutes, 0.20306849479675293 seconds

Avg val. time: 0.0 hours, 0.0 minutes, 0.21162538528442382 seconds
Avg batch val. time: 0.02116253852844238 seconds
Avg sample val. time: 0.0003332683232825572 seconds
Epoch 6 Validation Summary: epoch: 6.000000 | loss: 3.265884 | 
Epoch 7 Training Summary: epoch: 7.000000 | loss: 1.210076 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 1.9142124652862549 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.9816241604941232 seconds
Avg batch train. time: 0.06605413868313743 seconds
Avg sample train. time: 0.0010402226564273612 seconds
Epoch 8 Training Summary: epoch: 8.000000 | loss: 1.384695 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 1.887998104095459 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.9699209034442902 seconds
Avg batch train. time: 0.06566403011480967 seconds
Avg sample train. time: 0.0010340792144064516 seconds
Evaluating on validation set ...
Validation runtime: 0.0 hours, 0.0 minutes, 0.2060227394104004 seconds

Avg val. time: 0.0 hours, 0.0 minutes, 0.21069161097208658 seconds
Avg batch val. time: 0.021069161097208657 seconds
Avg sample val. time: 0.00033179781255446707 seconds
Epoch 8 Validation Summary: epoch: 8.000000 | loss: 3.740031 | 
Epoch 9 Training Summary: epoch: 9.000000 | loss: 1.656612 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 1.8574140071868896 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.9574201371934679 seconds
Avg batch train. time: 0.06524733790644893 seconds
Avg sample train. time: 0.0010275171323850226 seconds
Epoch 10 Training Summary: epoch: 10.000000 | loss: 1.990995 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 1.8642463684082031 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.9481027603149415 seconds
Avg batch train. time: 0.06493675867716471 seconds
Avg sample train. time: 0.0010226261209002317 seconds
Evaluating on validation set ...
Validation runtime: 0.0 hours, 0.0 minutes, 0.23900079727172852 seconds

Avg val. time: 0.0 hours, 0.0 minutes, 0.214735780443464 seconds
Avg batch val. time: 0.0214735780443464 seconds
Avg sample val. time: 0.00033816658337553385 seconds
Epoch 10 Validation Summary: epoch: 10.000000 | loss: 5.096721 | 
Best loss was 1.1635783218023346. Other metrics: OrderedDict([('epoch', 4), ('loss', 1.1635783218023346)])
All Done!
Total runtime: 0.0 hours, 0.0 minutes, 24.442296981811523 seconds

