Running:
main.py --output_dir experiments/salvador_83248/ --comment regression for salvador_83248 --name salvador_83248_Regression --records_file experiments/salvador_83248/salvador_83248_Regression.xls --data_dir datasets/files/salvador_83248/ --data_class wf --pattern TRAIN --val_pattern TEST --epochs 10 --lr 0.0001 --optimizer RAdam --pos_encoding learnable --task regression

Using device: cpu
Loading and preprocessing data ...
1919 samples may be used for training
640 samples will be used for validation
0 samples will be used for testing
Creating model ...
Model:
TSTransformerEncoderClassiregressor(
  (project_inp): Linear(in_features=5, out_features=64, bias=True)
  (pos_enc): LearnablePositionalEncoding(
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (transformer_encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): TransformerBatchNormEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (linear1): Linear(in_features=64, out_features=256, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=256, out_features=64, bias=True)
        (norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerBatchNormEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (linear1): Linear(in_features=64, out_features=256, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=256, out_features=64, bias=True)
        (norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
      (2): TransformerBatchNormEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (linear1): Linear(in_features=64, out_features=256, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=256, out_features=64, bias=True)
        (norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (dropout1): Dropout(p=0.1, inplace=False)
  (output_layer): Linear(in_features=1536, out_features=1, bias=True)
)
Total number of parameters: 153409
Trainable parameters: 153409
Evaluating on validation set ...
Validation runtime: 0.0 hours, 0.0 minutes, 0.18092942237854004 seconds

Avg val. time: 0.0 hours, 0.0 minutes, 0.18092942237854004 seconds
Avg batch val. time: 0.018092942237854005 seconds
Avg sample val. time: 0.0002827022224664688 seconds
Epoch 0 Validation Summary: epoch: 0.000000 | loss: 660.048572 | 
Starting training...
Epoch 1 Training Summary: epoch: 1.000000 | loss: 712.581368 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 1.7455439567565918 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7455439567565918 seconds
Avg batch train. time: 0.05818479855855306 seconds
Avg sample train. time: 0.0009096112333280833 seconds
Evaluating on validation set ...
Validation runtime: 0.0 hours, 0.0 minutes, 0.1939997673034668 seconds

Avg val. time: 0.0 hours, 0.0 minutes, 0.18746459484100342 seconds
Avg batch val. time: 0.018746459484100343 seconds
Avg sample val. time: 0.00029291342943906786 seconds
Epoch 1 Validation Summary: epoch: 1.000000 | loss: 705.010150 | 
Epoch 2 Training Summary: epoch: 2.000000 | loss: 707.409281 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 1.8201169967651367 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7828304767608643 seconds
Avg batch train. time: 0.059427682558695474 seconds
Avg sample train. time: 0.0009290414157169693 seconds
Evaluating on validation set ...
Validation runtime: 0.0 hours, 0.0 minutes, 0.17100167274475098 seconds

Avg val. time: 0.0 hours, 0.0 minutes, 0.1819769541422526 seconds
Avg batch val. time: 0.018197695414225258 seconds
Avg sample val. time: 0.00028433899084726966 seconds
Epoch 2 Validation Summary: epoch: 2.000000 | loss: 698.760065 | 
Epoch 3 Training Summary: epoch: 3.000000 | loss: 697.490360 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 1.8025920391082764 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7894176642100017 seconds
Avg batch train. time: 0.05964725547366672 seconds
Avg sample train. time: 0.0009324740303335079 seconds
Epoch 4 Training Summary: epoch: 4.000000 | loss: 685.679301 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 1.7716710567474365 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7849810123443604 seconds
Avg batch train. time: 0.05949936707814534 seconds
Avg sample train. time: 0.0009301620700074832 seconds
Evaluating on validation set ...
Validation runtime: 0.0 hours, 0.0 minutes, 0.2240009307861328 seconds

Avg val. time: 0.0 hours, 0.0 minutes, 0.19248294830322266 seconds
Avg batch val. time: 0.019248294830322265 seconds
Avg sample val. time: 0.0003007546067237854 seconds
Epoch 4 Validation Summary: epoch: 4.000000 | loss: 677.926227 | 
Epoch 5 Training Summary: epoch: 5.000000 | loss: 670.561775 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 1.940866470336914 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8161581039428711 seconds
Avg batch train. time: 0.06053860346476237 seconds
Avg sample train. time: 0.0009464086002828928 seconds
Epoch 6 Training Summary: epoch: 6.000000 | loss: 652.724407 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 1.8330092430114746 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8189666271209717 seconds
Avg batch train. time: 0.06063222090403239 seconds
Avg sample train. time: 0.0009478721350291671 seconds
Evaluating on validation set ...
Validation runtime: 0.0 hours, 0.0 minutes, 0.2100062370300293 seconds

Avg val. time: 0.0 hours, 0.0 minutes, 0.19598760604858398 seconds
Avg batch val. time: 0.0195987606048584 seconds
Avg sample val. time: 0.0003062306344509125 seconds
Epoch 6 Validation Summary: epoch: 6.000000 | loss: 646.102795 | 
Epoch 7 Training Summary: epoch: 7.000000 | loss: 630.306463 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 1.7830383777618408 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8138340200696672 seconds
Avg batch train. time: 0.06046113400232224 seconds
Avg sample train. time: 0.0009451975091556369 seconds
Epoch 8 Training Summary: epoch: 8.000000 | loss: 607.368822 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 1.7946486473083496 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8114358484745026 seconds
Avg batch train. time: 0.060381194949150084 seconds
Avg sample train. time: 0.0009439478105651394 seconds
Evaluating on validation set ...
Validation runtime: 0.0 hours, 0.0 minutes, 0.22404861450195312 seconds

Avg val. time: 0.0 hours, 0.0 minutes, 0.20066444079081217 seconds
Avg batch val. time: 0.020066444079081217 seconds
Avg sample val. time: 0.000313538188735644 seconds
Epoch 8 Validation Summary: epoch: 8.000000 | loss: 598.173212 | 
Epoch 9 Training Summary: epoch: 9.000000 | loss: 580.812791 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 1.8955423831939697 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8207810189988878 seconds
Avg batch train. time: 0.06069270063329626 seconds
Avg sample train. time: 0.0009488176232406919 seconds
Epoch 10 Training Summary: epoch: 10.000000 | loss: 550.677363 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 1.8511693477630615 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.8238198518753053 seconds
Avg batch train. time: 0.060793995062510174 seconds
Avg sample train. time: 0.0009504011734629001 seconds
Evaluating on validation set ...
Validation runtime: 0.0 hours, 0.0 minutes, 0.2240006923675537 seconds

Avg val. time: 0.0 hours, 0.0 minutes, 0.20399819101606095 seconds
Avg batch val. time: 0.020399819101606095 seconds
Avg sample val. time: 0.00031874717346259523 seconds
Epoch 10 Validation Summary: epoch: 10.000000 | loss: 534.340808 | 
Best loss was 534.3408081054688. Other metrics: OrderedDict([('epoch', 10), ('loss', 534.3408081054688)])
All Done!
Total runtime: 0.0 hours, 0.0 minutes, 23.05879259109497 seconds

