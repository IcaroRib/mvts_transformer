Running:
main.py --output_dir experiments/salvador_83248/ --comment regression for salvador_83248 --name salvador_83248_Regression --records_file experiments/salvador_83248/salvador_83248_Regression.xls --data_dir datasets/files/salvador_83248/ --data_class wf --pattern TRAIN --val_pattern TEST --epochs 10 --lr 0.001 --optimizer RAdam --pos_encoding learnable --task regression

Using device: cpu
Loading and preprocessing data ...
1919 samples may be used for training
640 samples will be used for validation
0 samples will be used for testing
Creating model ...
Model:
TSTransformerEncoderClassiregressor(
  (project_inp): Linear(in_features=5, out_features=64, bias=True)
  (pos_enc): LearnablePositionalEncoding(
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (transformer_encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): TransformerBatchNormEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (linear1): Linear(in_features=64, out_features=256, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=256, out_features=64, bias=True)
        (norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerBatchNormEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (linear1): Linear(in_features=64, out_features=256, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=256, out_features=64, bias=True)
        (norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
      (2): TransformerBatchNormEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (linear1): Linear(in_features=64, out_features=256, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=256, out_features=64, bias=True)
        (norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (dropout1): Dropout(p=0.1, inplace=False)
  (output_layer): Linear(in_features=1536, out_features=1, bias=True)
)
Total number of parameters: 153409
Trainable parameters: 153409
Evaluating on validation set ...
Validation runtime: 0.0 hours, 0.0 minutes, 0.18999981880187988 seconds

Avg val. time: 0.0 hours, 0.0 minutes, 0.18999981880187988 seconds
Avg batch val. time: 0.018999981880187988 seconds
Avg sample val. time: 0.0002968747168779373 seconds
Epoch 0 Validation Summary: epoch: 0.000000 | loss: 687.944440 | 
Starting training...
Epoch 1 Training Summary: epoch: 1.000000 | loss: 687.997549 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 1.5844125747680664 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.5844125747680664 seconds
Avg batch train. time: 0.05281375249226888 seconds
Avg sample train. time: 0.0008256449060802847 seconds
Evaluating on validation set ...
Validation runtime: 0.0 hours, 0.0 minutes, 0.21192240715026855 seconds

Avg val. time: 0.0 hours, 0.0 minutes, 0.20096111297607422 seconds
Avg batch val. time: 0.02009611129760742 seconds
Avg sample val. time: 0.00031400173902511596 seconds
Epoch 1 Validation Summary: epoch: 1.000000 | loss: 657.175574 | 
Epoch 2 Training Summary: epoch: 2.000000 | loss: 613.788002 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 1.9481592178344727 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.7662858963012695 seconds
Avg batch train. time: 0.05887619654337565 seconds
Avg sample train. time: 0.0009204199563841946 seconds
Evaluating on validation set ...
Validation runtime: 0.0 hours, 0.0 minutes, 0.22793102264404297 seconds

Avg val. time: 0.0 hours, 0.0 minutes, 0.20995108286539713 seconds
Avg batch val. time: 0.020995108286539714 seconds
Avg sample val. time: 0.00032804856697718303 seconds
Epoch 2 Validation Summary: epoch: 2.000000 | loss: 558.827304 | 
Epoch 3 Training Summary: epoch: 3.000000 | loss: 487.720242 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 2.1032209396362305 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.878597577412923 seconds
Avg batch train. time: 0.06261991924709744 seconds
Avg sample train. time: 0.000978946105999439 seconds
Epoch 4 Training Summary: epoch: 4.000000 | loss: 330.603616 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 2.053607940673828 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.9223501682281494 seconds
Avg batch train. time: 0.06407833894093831 seconds
Avg sample train. time: 0.0010017457885503644 seconds
Evaluating on validation set ...
Validation runtime: 0.0 hours, 0.0 minutes, 0.24183225631713867 seconds

Avg val. time: 0.0 hours, 0.0 minutes, 0.21792137622833252 seconds
Avg batch val. time: 0.021792137622833253 seconds
Avg sample val. time: 0.0003405021503567696 seconds
Epoch 4 Validation Summary: epoch: 4.000000 | loss: 251.178819 | 
Epoch 5 Training Summary: epoch: 5.000000 | loss: 174.282589 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 2.1300575733184814 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.9638916492462157 seconds
Avg batch train. time: 0.06546305497487385 seconds
Avg sample train. time: 0.00102339325130079 seconds
Epoch 6 Training Summary: epoch: 6.000000 | loss: 56.416612 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 2.0587687492370605 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.97970449924469 seconds
Avg batch train. time: 0.065990149974823 seconds
Avg sample train. time: 0.00103163340242037 seconds
Evaluating on validation set ...
Validation runtime: 0.0 hours, 0.0 minutes, 0.2200000286102295 seconds

Avg val. time: 0.0 hours, 0.0 minutes, 0.2183371067047119 seconds
Avg batch val. time: 0.02183371067047119 seconds
Avg sample val. time: 0.00034115172922611237 seconds
Epoch 6 Validation Summary: epoch: 6.000000 | loss: 17.700249 | 
Epoch 7 Training Summary: epoch: 7.000000 | loss: 10.164433 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 2.0425450801849365 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.9886817250932967 seconds
Avg batch train. time: 0.06628939083644322 seconds
Avg sample train. time: 0.0010363114773805611 seconds
Epoch 8 Training Summary: epoch: 8.000000 | loss: 4.262479 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 2.027005910873413 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.9934722483158112 seconds
Avg batch train. time: 0.06644907494386038 seconds
Avg sample train. time: 0.0010388078417487292 seconds
Evaluating on validation set ...
Validation runtime: 0.0 hours, 0.0 minutes, 0.22052502632141113 seconds

Avg val. time: 0.0 hours, 0.0 minutes, 0.21870175997416177 seconds
Avg batch val. time: 0.021870175997416176 seconds
Avg sample val. time: 0.00034172149995962775 seconds
Epoch 8 Validation Summary: epoch: 8.000000 | loss: 3.822135 | 
Epoch 9 Training Summary: epoch: 9.000000 | loss: 2.377167 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 2.051011562347412 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 1.9998655054304335 seconds
Avg batch train. time: 0.06666218351434779 seconds
Avg sample train. time: 0.0010421393983483238 seconds
Epoch 10 Training Summary: epoch: 10.000000 | loss: 1.430335 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 2.1078813076019287 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 2.010667085647583 seconds
Avg batch train. time: 0.06702223618825277 seconds
Avg sample train. time: 0.001047768153021148 seconds
Evaluating on validation set ...
Validation runtime: 0.0 hours, 0.0 minutes, 0.22121191024780273 seconds

Avg val. time: 0.0 hours, 0.0 minutes, 0.2190603528703962 seconds
Avg batch val. time: 0.021906035287039622 seconds
Avg sample val. time: 0.0003422818013599941 seconds
Epoch 10 Validation Summary: epoch: 10.000000 | loss: 3.536526 | 
Best loss was 3.5365261793136598. Other metrics: OrderedDict([('epoch', 10), ('loss', 3.5365261793136598)])
All Done!
Total runtime: 0.0 hours, 0.0 minutes, 25.105346202850342 seconds

