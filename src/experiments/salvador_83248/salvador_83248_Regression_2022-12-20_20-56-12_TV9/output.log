Running:
main.py --output_dir experiments/salvador_83248/ --comment regression for salvador_83248 --name salvador_83248_Regression --records_file experiments/salvador_83248/salvador_83248_Regression.xls --data_dir datasets/files/salvador_83248/ --data_class wf --pattern TRAIN --val_pattern TEST --epochs 10 --lr 0.005 --optimizer RAdam --pos_encoding learnable --task regression

Using device: cpu
Loading and preprocessing data ...
1919 samples may be used for training
640 samples will be used for validation
0 samples will be used for testing
Creating model ...
Model:
TSTransformerEncoderClassiregressor(
  (project_inp): Linear(in_features=5, out_features=64, bias=True)
  (pos_enc): LearnablePositionalEncoding(
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (transformer_encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): TransformerBatchNormEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (linear1): Linear(in_features=64, out_features=256, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=256, out_features=64, bias=True)
        (norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerBatchNormEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (linear1): Linear(in_features=64, out_features=256, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=256, out_features=64, bias=True)
        (norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
      (2): TransformerBatchNormEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (linear1): Linear(in_features=64, out_features=256, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=256, out_features=64, bias=True)
        (norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (dropout1): Dropout(p=0.1, inplace=False)
  (output_layer): Linear(in_features=1536, out_features=1, bias=True)
)
Total number of parameters: 153409
Trainable parameters: 153409
Evaluating on validation set ...
Validation runtime: 0.0 hours, 0.0 minutes, 0.2330024242401123 seconds

Avg val. time: 0.0 hours, 0.0 minutes, 0.2330024242401123 seconds
Avg batch val. time: 0.02330024242401123 seconds
Avg sample val. time: 0.0003640662878751755 seconds
Epoch 0 Validation Summary: epoch: 0.000000 | loss: 807.181598 | 
Starting training...
Epoch 1 Training Summary: epoch: 1.000000 | loss: 614.126429 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 2.545898914337158 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 2.545898914337158 seconds
Avg batch train. time: 0.08486329714457194 seconds
Avg sample train. time: 0.0013266799970490662 seconds
Evaluating on validation set ...
Validation runtime: 0.0 hours, 0.0 minutes, 0.3599991798400879 seconds

Avg val. time: 0.0 hours, 0.0 minutes, 0.2965008020401001 seconds
Avg batch val. time: 0.02965008020401001 seconds
Avg sample val. time: 0.0004632825031876564 seconds
Epoch 1 Validation Summary: epoch: 1.000000 | loss: 435.502933 | 
Epoch 2 Training Summary: epoch: 2.000000 | loss: 268.538437 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 2.893199920654297 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 2.7195494174957275 seconds
Avg batch train. time: 0.09065164724985758 seconds
Avg sample train. time: 0.0014171700977049127 seconds
Evaluating on validation set ...
Validation runtime: 0.0 hours, 0.0 minutes, 0.2755463123321533 seconds

Avg val. time: 0.0 hours, 0.0 minutes, 0.28951597213745117 seconds
Avg batch val. time: 0.028951597213745118 seconds
Avg sample val. time: 0.00045236870646476747 seconds
Epoch 2 Validation Summary: epoch: 2.000000 | loss: 89.775787 | 
Epoch 3 Training Summary: epoch: 3.000000 | loss: 17.093921 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 2.759866714477539 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 2.7329885164896646 seconds
Avg batch train. time: 0.09109961721632215 seconds
Avg sample train. time: 0.001424173275919575 seconds
Epoch 4 Training Summary: epoch: 4.000000 | loss: 1.819972 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 2.9068732261657715 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 2.7764596939086914 seconds
Avg batch train. time: 0.09254865646362305 seconds
Avg sample train. time: 0.001446826312615264 seconds
Evaluating on validation set ...
Validation runtime: 0.0 hours, 0.0 minutes, 0.3170011043548584 seconds

Avg val. time: 0.0 hours, 0.0 minutes, 0.296387255191803 seconds
Avg batch val. time: 0.029638725519180297 seconds
Avg sample val. time: 0.00046310508623719214 seconds
Epoch 4 Validation Summary: epoch: 4.000000 | loss: 5.424436 | 
Epoch 5 Training Summary: epoch: 5.000000 | loss: 0.643630 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 2.6125690937042236 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 2.7436815738677978 seconds
Avg batch train. time: 0.09145605246225992 seconds
Avg sample train. time: 0.0014297454788263666 seconds
Epoch 6 Training Summary: epoch: 6.000000 | loss: 0.536555 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 2.340728521347046 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 2.676522731781006 seconds
Avg batch train. time: 0.0892174243927002 seconds
Avg sample train. time: 0.0013947486877441406 seconds
Evaluating on validation set ...
Validation runtime: 0.0 hours, 0.0 minutes, 0.2689955234527588 seconds

Avg val. time: 0.0 hours, 0.0 minutes, 0.2909089088439941 seconds
Avg batch val. time: 0.029090890884399413 seconds
Avg sample val. time: 0.0004545451700687408 seconds
Epoch 6 Validation Summary: epoch: 6.000000 | loss: 3.090635 | 
Epoch 7 Training Summary: epoch: 7.000000 | loss: 0.531710 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 2.1696560382843018 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 2.6041132041386197 seconds
Avg batch train. time: 0.08680377347128733 seconds
Avg sample train. time: 0.0013570157395198644 seconds
Epoch 8 Training Summary: epoch: 8.000000 | loss: 0.448180 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 2.689939260482788 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 2.6148414611816406 seconds
Avg batch train. time: 0.08716138203938802 seconds
Avg sample train. time: 0.0013626062851389478 seconds
Evaluating on validation set ...
Validation runtime: 0.0 hours, 0.0 minutes, 0.29007720947265625 seconds

Avg val. time: 0.0 hours, 0.0 minutes, 0.2907702922821045 seconds
Avg batch val. time: 0.029077029228210448 seconds
Avg sample val. time: 0.00045432858169078825 seconds
Epoch 8 Validation Summary: epoch: 8.000000 | loss: 1.785044 | 
Epoch 9 Training Summary: epoch: 9.000000 | loss: 0.475509 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 2.556089162826538 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 2.6083134280310736 seconds
Avg batch train. time: 0.08694378093436912 seconds
Avg sample train. time: 0.001359204496107907 seconds
Epoch 10 Training Summary: epoch: 10.000000 | loss: 0.496415 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 2.4403812885284424 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 2.5915202140808105 seconds
Avg batch train. time: 0.08638400713602702 seconds
Avg sample train. time: 0.0013504534726841118 seconds
Evaluating on validation set ...
Validation runtime: 0.0 hours, 0.0 minutes, 0.3100008964538574 seconds

Avg val. time: 0.0 hours, 0.0 minutes, 0.2935175214494978 seconds
Avg batch val. time: 0.029351752144949776 seconds
Avg sample val. time: 0.00045862112726484025 seconds
Epoch 10 Validation Summary: epoch: 10.000000 | loss: 1.695832 | 
Best loss was 1.695832324028015. Other metrics: OrderedDict([('epoch', 10), ('loss', 1.695832324028015)])
All Done!
Total runtime: 0.0 hours, 0.0 minutes, 32.194019079208374 seconds

