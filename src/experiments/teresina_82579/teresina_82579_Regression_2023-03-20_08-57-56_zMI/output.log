Running:
main.py --output_dir experiments/teresina_82579/ --comment regression for teresina_82579 --name teresina_82579_Regression --records_file experiments/teresina_82579/teresina_82579_Regression.xls --data_dir datasets/files/teresina_82579/ --data_class wf --pattern TRAIN --val_pattern TEST --epochs 40 --lr 0.001 --optimizer RAdam --pos_encoding learnable --task regression

Using device: cpu
Loading and preprocessing data ...
229 samples may be used for training
64 samples will be used for validation
0 samples will be used for testing
Creating model ...
Model:
TSTransformerEncoderClassiregressor(
  (project_inp): Linear(in_features=5, out_features=64, bias=True)
  (pos_enc): LearnablePositionalEncoding(
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (transformer_encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): TransformerBatchNormEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (linear1): Linear(in_features=64, out_features=256, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=256, out_features=64, bias=True)
        (norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerBatchNormEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (linear1): Linear(in_features=64, out_features=256, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=256, out_features=64, bias=True)
        (norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
      (2): TransformerBatchNormEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (linear1): Linear(in_features=64, out_features=256, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=256, out_features=64, bias=True)
        (norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (dropout1): Dropout(p=0.1, inplace=False)
  (output_layer): Linear(in_features=1536, out_features=1, bias=True)
)
Total number of parameters: 153409
Trainable parameters: 153409
Evaluating on validation set ...
Validation runtime: 0.0 hours, 0.0 minutes, 0.023000240325927734 seconds

Avg val. time: 0.0 hours, 0.0 minutes, 0.023000240325927734 seconds
Avg batch val. time: 0.023000240325927734 seconds
Avg sample val. time: 0.00035937875509262085 seconds
Epoch 0 Validation Summary: epoch: 0.000000 | loss: 16.840242 | 
Starting training...
Epoch 1 Training Summary: epoch: 1.000000 | loss: 0.173595 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 0.2500009536743164 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 0.2500009536743164 seconds
Avg batch train. time: 0.0625002384185791 seconds
Avg sample train. time: 0.0010917072212852244 seconds
Evaluating on validation set ...
Validation runtime: 0.0 hours, 0.0 minutes, 0.0260007381439209 seconds

Avg val. time: 0.0 hours, 0.0 minutes, 0.024500489234924316 seconds
Avg batch val. time: 0.024500489234924316 seconds
Avg sample val. time: 0.00038282014429569244 seconds
Epoch 1 Validation Summary: epoch: 1.000000 | loss: 0.284552 | 
Epoch 2 Training Summary: epoch: 2.000000 | loss: 0.115524 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 0.2520017623901367 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 0.25100135803222656 seconds
Avg batch train. time: 0.06275033950805664 seconds
Avg sample train. time: 0.001096075799267365 seconds
Evaluating on validation set ...
Validation runtime: 0.0 hours, 0.0 minutes, 0.02100086212158203 seconds

Avg val. time: 0.0 hours, 0.0 minutes, 0.023333946863810223 seconds
Avg batch val. time: 0.023333946863810223 seconds
Avg sample val. time: 0.0003645929197470347 seconds
Epoch 2 Validation Summary: epoch: 2.000000 | loss: 0.142919 | 
Epoch 3 Training Summary: epoch: 3.000000 | loss: 0.097144 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 0.2549934387207031 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 0.25233205159505206 seconds
Avg batch train. time: 0.06308301289876302 seconds
Avg sample train. time: 0.0011018866881880003 seconds
Epoch 4 Training Summary: epoch: 4.000000 | loss: 0.102384 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 0.26001548767089844 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 0.25425291061401367 seconds
Avg batch train. time: 0.06356322765350342 seconds
Avg sample train. time: 0.0011102747188384877 seconds
Evaluating on validation set ...
Validation runtime: 0.0 hours, 0.0 minutes, 0.021986007690429688 seconds

Avg val. time: 0.0 hours, 0.0 minutes, 0.022996962070465088 seconds
Avg batch val. time: 0.022996962070465088 seconds
Avg sample val. time: 0.000359327532351017 seconds
Epoch 4 Validation Summary: epoch: 4.000000 | loss: 0.104159 | 
Epoch 5 Training Summary: epoch: 5.000000 | loss: 0.105170 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 0.254000186920166 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 0.25420236587524414 seconds
Avg batch train. time: 0.06355059146881104 seconds
Avg sample train. time: 0.0011100539994552145 seconds
Epoch 6 Training Summary: epoch: 6.000000 | loss: 0.078442 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 0.30099940299987793 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 0.2620018720626831 seconds
Avg batch train. time: 0.06550046801567078 seconds
Avg sample train. time: 0.0011441129784396642 seconds
Evaluating on validation set ...
Validation runtime: 0.0 hours, 0.0 minutes, 0.020001649856567383 seconds

Avg val. time: 0.0 hours, 0.0 minutes, 0.022397899627685548 seconds
Avg batch val. time: 0.022397899627685548 seconds
Avg sample val. time: 0.0003499671816825867 seconds
Epoch 6 Validation Summary: epoch: 6.000000 | loss: 0.093111 | 
Epoch 7 Training Summary: epoch: 7.000000 | loss: 0.087789 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 0.26799845695495605 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 0.2628585270472935 seconds
Avg batch train. time: 0.06571463176182338 seconds
Avg sample train. time: 0.001147853829900845 seconds
Epoch 8 Training Summary: epoch: 8.000000 | loss: 0.093545 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 0.28100156784057617 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 0.26512640714645386 seconds
Avg batch train. time: 0.06628160178661346 seconds
Avg sample train. time: 0.0011577572364473967 seconds
Evaluating on validation set ...
Validation runtime: 0.0 hours, 0.0 minutes, 0.02400827407836914 seconds

Avg val. time: 0.0 hours, 0.0 minutes, 0.022666295369466145 seconds
Avg batch val. time: 0.022666295369466145 seconds
Avg sample val. time: 0.0003541608651479085 seconds
Epoch 8 Validation Summary: epoch: 8.000000 | loss: 0.101472 | 
Epoch 9 Training Summary: epoch: 9.000000 | loss: 0.077100 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 0.289003849029541 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 0.26777945624457467 seconds
Avg batch train. time: 0.06694486406114367 seconds
Avg sample train. time: 0.001169342603688099 seconds
Epoch 10 Training Summary: epoch: 10.000000 | loss: 0.075879 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 0.2569999694824219 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 0.26670150756835936 seconds
Avg batch train. time: 0.06667537689208984 seconds
Avg sample train. time: 0.0011646354042286434 seconds
Evaluating on validation set ...
Validation runtime: 0.0 hours, 0.0 minutes, 0.024001121520996094 seconds

Avg val. time: 0.0 hours, 0.0 minutes, 0.02285698481968471 seconds
Avg batch val. time: 0.02285698481968471 seconds
Avg sample val. time: 0.0003571403878075736 seconds
Epoch 10 Validation Summary: epoch: 10.000000 | loss: 0.096677 | 
Epoch 11 Training Summary: epoch: 11.000000 | loss: 0.065616 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 0.26199960708618164 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 0.26627406206997956 seconds
Avg batch train. time: 0.06656851551749489 seconds
Avg sample train. time: 0.0011627688299999108 seconds
Epoch 12 Training Summary: epoch: 12.000000 | loss: 0.091547 | 
Epoch runtime: 0.0 hours, 0.0 minutes, 0.2625153064727783 seconds

Avg epoch train. time: 0.0 hours, 0.0 minutes, 0.26596083243687946 seconds
Avg batch train. time: 0.06649020810921986 seconds
Avg sample train. time: 0.0011614010150082072 seconds
Evaluating on validation set ...
Validation runtime: 0.0 hours, 0.0 minutes, 0.020000696182250977 seconds

Avg val. time: 0.0 hours, 0.0 minutes, 0.022499948740005493 seconds
Avg batch val. time: 0.022499948740005493 seconds
Avg sample val. time: 0.00035156169906258583 seconds
Epoch 12 Validation Summary: epoch: 12.000000 | loss: 0.103623 | 
